---
# Please keep this file alphabetically sorted!
commons:
  cask: CASK
  cdap: CDAP
  entity:
    application:
      plural: Applications
      short-singular: App
      short-plural: Apps
      singular: Application
    artifact:
      plural: Artifacts
      singular: Artifact
    cdap-data-pipeline:
      plural: Data Pipelines
      singular: Data Pipeline
    cdap-data-streams:
      plural: Data Streams
      singular: Data Stream
    dataset:
      plural: Datasets
      singular: Dataset
    datasetinstance:
      plural: Datasets
      singular: Dataset
    flow:
      plural: Flows
      singular: Flow
    mapreduce:
      plural: Mapreduce
      singular: Mapreduce
    program:
      plural: Programs
      singular: Program
    service:
      plural: Services
      singular: Service
    spark:
      plural: Spark
      singular: Spark
    stream:
      plural: Streams
      singular: Stream
    worker:
      plural: Workers
      singular: Worker
    workflow:
      plural: Workflows
      singular: Workflow
    view:
      plural: Stream Views
      singular: Stream View
  hydrator: Cask Hydrator
  market: Cask Market
  resource-center: Resource Center
  tracker: Cask Tracker
  nameLabel: Name
  descriptionLabel: Description
  formatLabel: Format
  schemaLabel: Schema
features:
  Home:
    emptyMessage: MODIFY THIS!!!!!!!!!!
    Cards:
      type: "Type: "
    Header:
      filters: Filters
      search-placeholder: Search cards
      sort: Sort
      sortOptions:
        nameAsc: A - Z
        nameDesc: Z - A
  Management:
    Component-Overview:
      cards:
        cdh: CDH
        yarn: YARN
        hdfs: HDFS
        zookeeper: Zookeeper
        kafka: Kafka
        spark: Spark

  Market:
    search-placeholder: Search
    tabs:
      all: All
      applications: Applications
      artifacts: Artifacts
      dashboards: Dashboards
      datapacks: Datapacks
      datasets: Datasets
      examples: Examples
      pipelines: Pipelines
      plugins: Plugins
      useCases: Use Cases
    action-types:
      create_stream:
        name: Create
      create_app:
        name: Create
      create_pipeline:
        name: Create
      create_artifact:
        name: Create
      informational:
        name: Download
      load_datapack:
        name: Load
  MarketEntityModal:
    version: "Version :"
  Navbar:
    CDAP:
      dashboard: Dashboard
      home: Home
      management: Management
    HeaderActions:
      caskHome: Cask Home
      documentation: Documentation
      logout: Logout
      signedInAs: Signed in as
      support: Support
    Sidebar:
      extension: "Extensions:"
  Resource-Center:
    Stream:
      label: Stream
      description: Streams are ways for ingesting data on to HDFS. To ingest in real-time or batch use Stream.
      actionbtn0: Create
    Application:
      label: Application
      description: Create a custom application by uploading the Application JAR or create new instance of application using existing JAR.
      actionbtn0: Upload
      actionbtn-1: Create
    Stream-View:
      label: Stream View
      description: Create a view over an existing Stream.
      actionbtn0: Create
    HydratorPipeline:
      label: Hydrator Pipeline
      description: Create a new Hydrator Pipeline for Batch and Real-time
      actionbtn0: Create
    Artifact:
      label: Artifact
      description: Upload an artifact
      actionbtn0: Upload
    Plugins:
      label: Plugins
      description: Upload and configure a plugin
      actionbtn0: Upload
  SplashScreen:
    buttons:
      getStarted: Read the Docs
      introduction: Intro to CDAP
      register: Register for Updates
    intro-message: Unified Integration Platform for Big Data
    title: Welcome to Cask Data Application Platform
    version-label: Version 4.0.0 Preview
  Wizard:
    Done: Done
    Informational:
      Step1:
        description: Steps to follow
        shorttitle: Information
        title: Info
      headerlabel: Information
    Skip: Skipped
    FailedMessage: Failed to {step}
    StreamCreate:
      Step1:
        shorttitle: General Information
        title: General
        description: Provide information about Stream you want to create.
        ttllabel: Event Life Time
        ttl-placeholder: Specify time to live events in seconds
      Step2:
        shorttitle: Setup Format and Schema
        title: Set Format and Schema
        description: Setting format and schema allows you to perform schema-on-read.
      Step3:
        shorttitle: Trigger Setup
        title: Setup Trigger
        description: Setting up Trigger configures system to notify systems observing to start processing.
        thresholdlabel: The stream will notify any observers upon reaching this threshold to start processing of the data in this Stream
        mblabel: Megabytes (MB)
      Step4:
        shorttitle: Upload Data
        title: Upload Data
        description: Upload Data to the Stream you created
      headerlabel: Create Stream
    UploadData:
      Step1:
        shorttitle: View Data
        title: View Data
        description: Shows the data for your reference that would be uploaded to a destination
      Step2:
        shorttitle: Select Destination
        title: Select Destination
        description: Select the destination where the data needs to be uploaded
        dataentitynameplaceholder: Dataset/Stream Name
        destinationtype: Destination Type
        destinationname: Destination Name
      headerlabel: Upload Data
    PublishPipeline:
      Step1:
        shorttitle: Configure pipeline
        title: Configure pipeline
        description: Specify the name of the pipeline
      pipelinenameplaceholder: Pipeline name
      headerlabel: Publish Pipeline
    HydratorPipeline:
      title: Hydrator Pipeline
      message: Please choose appropriate pipeline types to be created
      batchLinkLabel: Hydrator Batch Pipeline
      realtimeLinkLabel: Hydrator Realtime Pipeline
...
